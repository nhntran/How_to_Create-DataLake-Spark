{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT: DATA LAKE\n",
    "## ETL PIPELINE FOR SPARKIFY DATABASE - DATA LAKE ON S3\n",
    "\n",
    "## PART 2: VALIDATION ON THE SPARKIFY DATABASE\n",
    "\n",
    "### by Tran Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the data quality checks to make sure if the ETL pipeline successfully added all the records to the tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SET UP SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, max as max_\n",
    "from pyspark.sql.functions import *\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. LOAD AWS CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read config file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('credentials.cfg')\n",
    "# Retrieve value using config['KEYWORD']['SUBKEYWORD']\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. CREATE SPARK SESSION WITH HADOOP-AWS PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()\n",
    "### The package `org.apache.hadoop:hadoop-aws:2.7.0` allows you to connect aws S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PERFORM QUALITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for quality check\n",
    "def validate_table_insertion(table, id):\n",
    "    \"\"\"\n",
    "    Read the parquet file into dataframe, convert spark df to sql table\n",
    "    Check the table using sql queries\n",
    "    \"\"\"\n",
    "    ### load table\n",
    "    table_name = os.path.join(input_path, table)\n",
    "    parquetFile = spark.read.parquet(table_name)\n",
    "    ### print count\n",
    "    print('\\033[1m' + f\"Validate insertion from table {table}:\" + '\\033[0m')\n",
    "    print(\"Dimension of the table:\", parquetFile.count())\n",
    "    \n",
    "    ### convert df to sql table\n",
    "    parquetFile.createOrReplaceTempView(table)\n",
    "    \n",
    "    ### count unique\n",
    "    unique = spark.sql(f\"SELECT COUNT(DISTINCT {id}) count FROM {table};\")\n",
    "    print(\"Number of unique id: \", unique.select('count').collect()[0]['count'])\n",
    "    ### check null id\n",
    "    \n",
    "    null_id = spark.sql(f\"SELECT COUNT(*) count FROM {table} WHERE {id} = NULL;\")    \n",
    "    print(\"Number of null id: \", null_id.select('count').collect()[0]['count'])\n",
    "    \n",
    "    ### print some examples\n",
    "    print(\"Some examples from the table:\")\n",
    "    examples = spark.sql(f\"SELECT * FROM {table} LIMIT 5;\")\n",
    "    examples.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mValidate insertion from table songs:\u001b[0m\n",
      "Dimension of the table: 14896\n",
      "Number of unique id:  14896\n",
      "Number of null id:  0\n",
      "Some examples from the table:\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|           song_id|               title| duration|year|         artist_id|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "|SODUMDU12AC468A22B|We're Skrewed (Ot...| 249.5473|   0|ARHOSMU1242078130D|\n",
      "|SOTCIHX12A8C13DDD2|Finally_ as that ...|483.34322|2006|ARYOIZG1187FB41E30|\n",
      "|SOPSXLI12A6D4FA418|Practical Cats - ...|251.03628|   0|ARR79V31187FB5B96E|\n",
      "|SOUFBFK12A8C13D668|String Quartets O...|348.60363|   0|ARAILTA11F4C840A06|\n",
      "|SOROAMT12A8C13C6D0|Me gustan mas los...|101.85098|2008|ARWUDTF1187B9AA096|\n",
      "+------------------+--------------------+---------+----+------------------+\n",
      "\n",
      "\u001b[1mValidate insertion from table artists:\u001b[0m\n",
      "Dimension of the table: 10025\n",
      "Number of unique id:  9553\n",
      "Number of null id:  0\n",
      "Some examples from the table:\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "|         artist_id|           name|            location|latitude| longitude|\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "|ARSMEBG1187FB4D02B|    Kevin Ayers|Herne Bay, Kent, ...|51.37121|    1.1251|\n",
      "|ARM66431187FB4CD0B|            Ash|Downpatrick, Co. ...| 54.3274|  -5.70496|\n",
      "|ARNU0OM1187FB3F14A|    Larry Groce|          Dallas, TX|32.77815|  -96.7954|\n",
      "|ARY1VGA1187FB5A39E|   Tom Cochrane|Lynn Lake, Manito...|56.85147|-101.04893|\n",
      "|AR3UJPY1187FB5017B|Patience Dabany|Libreville, Gabon...|34.05349|-118.24532|\n",
      "+------------------+---------------+--------------------+--------+----------+\n",
      "\n",
      "\u001b[1mValidate insertion from table users:\u001b[0m\n",
      "Dimension of the table: 96\n",
      "Number of unique id:  96\n",
      "Number of null id:  0\n",
      "Some examples from the table:\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     51|      Maia|    Burke|     F| free|\n",
      "|     25|    Jayden|   Graves|     M| paid|\n",
      "|     42|    Harper|  Barrett|     M| paid|\n",
      "|     41|   Brayden|    Clark|     M| free|\n",
      "|     35|     Molly|   Taylor|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "\n",
      "\u001b[1mValidate insertion from table time:\u001b[0m\n",
      "Dimension of the table: 6813\n",
      "Number of unique id:  6813\n",
      "Number of null id:  0\n",
      "Some examples from the table:\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|          start_time|hour|day|week|weekday|year|month|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-15 08:36:...|   8| 15|  46|    Thu|2018|   11|\n",
      "|2018-11-15 11:02:...|  11| 15|  46|    Thu|2018|   11|\n",
      "|2018-11-21 07:26:...|   7| 21|  47|    Wed|2018|   11|\n",
      "|2018-11-21 09:55:...|   9| 21|  47|    Wed|2018|   11|\n",
      "|2018-11-21 10:49:...|  10| 21|  47|    Wed|2018|   11|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "\n",
      "\u001b[1mValidate insertion from table songplays:\u001b[0m\n",
      "Dimension of the table: 6820\n",
      "Number of unique id:  6813\n",
      "Number of null id:  0\n",
      "Some examples from the table:\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "|          start_time|user_id|level|song_id|artist_id|session_id|            location|          user_agent|\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "|2018-11-02 03:42:...|     15| paid|   null|     null|       172|Chicago-Napervill...|\"Mozilla/5.0 (X11...|\n",
      "|2018-11-02 05:09:...|     49| free|   null|     null|       179|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|2018-11-02 09:38:...|     50| free|   null|     null|       156|New Haven-Milford...|\"Mozilla/5.0 (Win...|\n",
      "|2018-11-02 10:13:...|     10| free|   null|     null|       182|Washington-Arling...|\"Mozilla/5.0 (Mac...|\n",
      "|2018-11-03 10:28:...|     95| paid|   null|     null|       152|   Winston-Salem, NC|\"Mozilla/5.0 (iPh...|\n",
      "+--------------------+-------+-----+-------+---------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_path = 'output' # location of all the tables\n",
    "tables = ['songs', 'artists', 'users', 'time', 'songplays']\n",
    "ids = [\"song_id\", \"artist_id\", \"user_id\", \"start_time\", \"start_time\"]\n",
    "\n",
    "### Perform all the check:\n",
    "for i in range(0, len(tables)):\n",
    "    validate_table_insertion(tables[i], ids[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
